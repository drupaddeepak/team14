"use client"

import { useState, useEffect } from "react"
import { useChat } from "ai/react"
import { Button } from "@/components/ui/button"
import { Card, CardContent } from "@/components/ui/card"
import { Input } from "@/components/ui/input"
import { ScrollArea } from "@/components/ui/scroll-area"
import { Mic, Send, Bot, Volume2, VolumeX, Brain } from "lucide-react"
import { Sidebar } from "@/components/sidebar"
import { ChatMessage } from "@/components/chat-message"
import { FileUpload } from "@/components/file-upload"
import { TTSSettings, type TTSSettings as TTSSettingsType } from "@/components/tts-settings"
import { DwaniLLMSettings, type DwaniLLMSettings as DwaniLLMSettingsType } from "@/components/dwani-llm-settings"
import { sendChatMessage } from "@/lib/api-client"

interface ChatSession {
  id: string
  title: string
  messages: any[]
  createdAt: Date
}

export default function SarathiAI() {
  const [selectedFile, setSelectedFile] = useState<File | null>(null)
  const [isListening, setIsListening] = useState(false)
  const [currentLanguage, setCurrentLanguage] = useState("en")
  const [chatSessions, setChatSessions] = useState<ChatSession[]>([])
  const [activeChatId, setActiveChatId] = useState<string | null>(null)
  const [ttsSettings, setTtsSettings] = useState<TTSSettingsType>({
    enabled: true,
    speed: 1.0,
    pitch: 1.0,
    speaker_id: "english_female",
    autoPlay: true,
  })
  const [showTTSSettings, setShowTTSSettings] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [dwaniLLMSettings, setDwaniLLMSettings] = useState<DwaniLLMSettingsType>({
    enabled: false,
    model: "indic-llm",
    temperature: 0.7,
    maxTokens: 1000,
    useIndic: true,
  })
  const [showDwaniLLMSettings, setShowDwaniLLMSettings] = useState(false)

  // Initialize speech synthesis voices
  useEffect(() => {
    if ("speechSynthesis" in window) {
      // Load voices
      const loadVoices = () => {
        const voices = window.speechSynthesis.getVoices()
        console.log("Available voices:", voices.length)
      }

      loadVoices()
      window.speechSynthesis.onvoiceschanged = loadVoices
    }
  }, [])

  const { messages, input, handleInputChange, handleSubmit, isLoading, setMessages } = useChat({
    api: "http://localhost:5000/api/chat",
    body: {
      language: currentLanguage,
      model: dwaniLLMSettings.model,
    },
    onFinish: (message) => {
      console.log("Chat response received:", message);
      // Convert response to speech
      if (ttsSettings.enabled && ttsSettings.autoPlay) {
        console.log("TTS enabled, converting to speech:", message.content);
        handleTextToSpeech(message.content)
      }
      // Update chat session
      console.log("Updating chat session with message:", message);
      updateChatSession(message)
    },
  })

  // Add debug log for messages array
  useEffect(() => {
    console.log("Messages array updated:", messages);
  }, [messages]);

  const createNewChat = () => {
    const newChatId = `chat-${Date.now()}`
    const newChat: ChatSession = {
      id: newChatId,
      title: currentLanguage === "hi" ? "‡§®‡§à ‡§ö‡•à‡§ü" : currentLanguage === "kn" ? "‡≤π‡≥ä‡≤∏ ‡≤ö‡≤æ‡≤ü‡≥ç" : "New Chat",
      messages: [],
      createdAt: new Date(),
    }

    setChatSessions((prev) => [newChat, ...prev])
    setActiveChatId(newChatId)
    setMessages([])
    setSelectedFile(null)
  }

  const switchToChat = (chatId: string) => {
    const chat = chatSessions.find((c) => c.id === chatId)
    if (chat) {
      setActiveChatId(chatId)
      setMessages(chat.messages)
    }
  }

  const updateChatSession = (newMessage: any) => {
    if (activeChatId) {
      setChatSessions((prev) =>
        prev.map((chat) =>
          chat.id === activeChatId
            ? {
                ...chat,
                messages: [...messages, newMessage],
                title:
                  chat.title === (currentLanguage === "hi" ? "‡§®‡§à ‡§ö‡•à‡§ü" : currentLanguage === "kn" ? "‡≤π‡≥ä‡≤∏ ‡≤ö‡≤æ‡≤ü‡≥ç" : "New Chat")
                    ? newMessage.content.slice(0, 30) + "..."
                    : chat.title,
              }
            : chat,
        ),
      )
    }
  }

  const deleteChat = (chatId: string) => {
    setChatSessions((prev) => prev.filter((chat) => chat.id !== chatId))

    if (activeChatId === chatId) {
      const remainingChats = chatSessions.filter((chat) => chat.id !== chatId)
      if (remainingChats.length > 0) {
        setActiveChatId(remainingChats[0].id)
        setMessages(remainingChats[0].messages)
      } else {
        setActiveChatId(null)
        setMessages([])
      }
    }
  }

  const handleTextToSpeech = async (text: string) => {
    if (!ttsSettings.enabled || !text.trim()) return

    console.log("TTS: Starting speech for:", text.substring(0, 50))

    // Stop any ongoing speech
    if ("speechSynthesis" in window) {
      window.speechSynthesis.cancel()
    }

    try {
      // Use browser TTS directly for reliability
      speakWithBrowserTTS(text)
    } catch (error) {
      console.error("TTS error:", error)
    }
  }

  const speakWithBrowserTTS = (text: string) => {
    if (!("speechSynthesis" in window)) {
      console.error("Speech synthesis not supported")
      return
    }

    const utterance = new SpeechSynthesisUtterance(text)

    // Language mapping
    const langMap: Record<string, string> = {
      en: "en-US",
      hi: "hi-IN",
      kn: "kn-IN",
      ta: "ta-IN",
      te: "te-IN",
      bn: "bn-IN",
      gu: "gu-IN",
      mr: "mr-IN",
      pa: "pa-IN",
      or: "or-IN",
    }

    utterance.lang = langMap[currentLanguage] || "en-US"
    utterance.rate = ttsSettings.speed
    utterance.pitch = ttsSettings.pitch
    utterance.volume = 1.0

    // Find the best voice for the language
    const voices = window.speechSynthesis.getVoices()
    const targetLang = langMap[currentLanguage] || "en-US"

    // Try to find exact language match
    let selectedVoice = voices.find((voice) => voice.lang === targetLang)

    // Fallback to language prefix match (e.g., "hi" matches "hi-IN")
    if (!selectedVoice) {
      const langPrefix = targetLang.split("-")[0]
      selectedVoice = voices.find((voice) => voice.lang.startsWith(langPrefix))
    }

    // Final fallback to English
    if (!selectedVoice) {
      selectedVoice = voices.find((voice) => voice.lang.startsWith("en"))
    }

    if (selectedVoice) {
      utterance.voice = selectedVoice
      console.log("Using voice:", selectedVoice.name, selectedVoice.lang)
    }

    utterance.onstart = () => {
      setIsSpeaking(true)
      console.log("TTS: Speech started")
    }

    utterance.onend = () => {
      setIsSpeaking(false)
      console.log("TTS: Speech ended")
    }

    utterance.onerror = (event) => {
      setIsSpeaking(false)
      console.error("TTS error:", event.error)
    }

    // Speak the text
    window.speechSynthesis.speak(utterance)
  }

  const stopSpeech = () => {
    if ("speechSynthesis" in window) {
      window.speechSynthesis.cancel()
      setIsSpeaking(false)
    }
  }

  const handleFileUpload = async (file: File) => {
    setSelectedFile(file)

    const formData = new FormData()
    formData.append("file", file)

    try {
      const response = await fetch("/api/process-pdf", {
        method: "POST",
        body: formData,
      })

      const result = await response.json()

      const syntheticEvent = {
        preventDefault: () => {},
        target: {
          value: `I've uploaded a government form: ${file.name}. Please analyze it and guide me on how to fill it out.`,
        },
      } as any

      handleInputChange(syntheticEvent)
      handleSubmit(syntheticEvent)
    } catch (error) {
      console.error("PDF processing error:", error)
    }
  }

  const startVoiceRecognition = () => {
    if ("webkitSpeechRecognition" in window) {
      const recognition = new (window as any).webkitSpeechRecognition()
      recognition.lang = currentLanguage === "hi" ? "hi-IN" : currentLanguage === "kn" ? "kn-IN" : "en-US"
      recognition.onstart = () => setIsListening(true)
      recognition.onend = () => setIsListening(false)
      recognition.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript
        const syntheticEvent = {
          preventDefault: () => {},
          target: { value: transcript },
        } as any
        handleInputChange(syntheticEvent)
      }
      recognition.start()
    }
  }

  const getWelcomeMessage = () => {
    switch (currentLanguage) {
      case "hi":
        return {
          title: "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§∏‡§æ‡§∞‡§•‡•Ä AI ‡§π‡•Ç‡§Ç",
          description:
            "‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§´‡•â‡§∞‡•ç‡§Æ ‡§ï‡§æ PDF ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§¨‡§§‡§æ‡§ä‡§Ç‡§ó‡§æ ‡§ï‡§ø ‡§á‡§∏‡•á ‡§ï‡•à‡§∏‡•á ‡§≠‡§∞‡§®‡§æ ‡§π‡•à‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç ‡§≠‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç‡•§",
        }
      case "kn":
        return {
          title: "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞! ‡≤®‡≤æ‡≤®‡≥Å ‡≤∏‡≤æ‡≤∞‡≤•‡≤ø AI",
          description:
            "‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤∏‡≤∞‡≥ç‡≤ï‡≤æ‡≤∞‡≤ø ‡≤∏‡≤π‡≤æ‡≤Ø‡≤ï. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤∏‡≤∞‡≥ç‡≤ï‡≤æ‡≤∞‡≤ø ‡≤´‡≤æ‡≤∞‡≥ç‡≤Æ‡≥ç PDF ‡≤Ö‡≤™‡≥ç‚Äå‡≤≤‡≥ã‡≤°‡≥ç ‡≤Æ‡≤æ‡≤°‡≤¨‡≤π‡≥Å‡≤¶‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤Ö‡≤¶‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥á‡≤ó‡≥Ü ‡≤≠‡≤∞‡≥ç‡≤§‡≤ø ‡≤Æ‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Ü‡≤Ç‡≤¶‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤¶‡≤∞‡≥ç‡≤∂‡≤® ‡≤®‡≥Ä‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü.",
        }
      case "ta":
        return {
          title: "‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç! ‡Æ®‡Ææ‡Æ©‡Øç ‡Æö‡Ææ‡Æ∞‡Æ§‡Æø AI",
          description:
            "‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÖ‡Æ∞‡Æö‡Ææ‡Æô‡Øç‡Æï ‡Æâ‡Æ§‡Æµ‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç. ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ®‡Øç‡Æ§ ‡ÆÖ‡Æ∞‡Æö‡Ææ‡Æô‡Øç‡Æï ‡Æ™‡Æü‡Æø‡Æµ‡Æ§‡Øç‡Æ§‡Æø‡Æ©‡Øç PDF ‡Æê ‡Æ™‡Æ§‡Æø‡Æµ‡Øá‡Æ±‡Øç‡Æ±‡Æ≤‡Ææ‡ÆÆ‡Øç, ‡ÆÖ‡Æ§‡Øà ‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æ®‡Æø‡Æ∞‡Æ™‡Øç‡Æ™‡ØÅ‡Æµ‡Æ§‡ØÅ ‡Æé‡Æ©‡Øç‡Æ±‡ØÅ ‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æµ‡Æ¥‡Æø‡Æï‡Ææ‡Æü‡Øç‡Æü‡ØÅ‡Æµ‡Øá‡Æ©‡Øç.",
        }
      case "te":
        return {
          title: "‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞®‡±á‡∞®‡±Å ‡∞∏‡∞æ‡∞∞‡∞•‡∞ø AI",
          description:
            "‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡∞ø‡∞®‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ ‡∞´‡∞æ‡∞∞‡∞Æ‡±ç PDF ‡∞®‡±Å ‡∞Ö‡∞™‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø ‡∞é‡∞≤‡∞æ ‡∞™‡±Ç‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡±ã ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞¶‡∞∞‡±ç‡∞∂‡∞®‡∞Ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å.",
        }
      case "bn":
        return {
          title: "‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞! ‡¶Ü‡¶Æ‡¶ø ‡¶∏‡¶æ‡¶∞‡¶•‡¶ø AI",
          description:
            "‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∏‡¶∞‡¶ï‡¶æ‡¶∞‡¶ø ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶∏‡¶∞‡¶ï‡¶æ‡¶∞‡¶ø ‡¶´‡¶∞‡ßç‡¶Æ‡ßá‡¶∞ PDF ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶§‡¶æ ‡¶™‡ßÇ‡¶∞‡¶£ ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá ‡¶§‡¶æ ‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶ó‡¶æ‡¶á‡¶° ‡¶ï‡¶∞‡¶¨‡•§",
        }
      default:
        return {
          title: "Namaste! I am Sarathi AI",
          description:
            "I am your government assistant. You can upload any government form PDF and I will guide you on how to fill it out. I can also provide voice responses.",
        }
    }
  }

  // Add debug log in the render section
  console.log("Rendering messages:", messages);

  return (
    <div className="flex h-screen bg-orange-50">
      <Sidebar
        currentLanguage={currentLanguage}
        onLanguageChange={setCurrentLanguage}
        chatSessions={chatSessions}
        activeChatId={activeChatId}
        onNewChat={createNewChat}
        onSwitchChat={switchToChat}
        onDeleteChat={deleteChat}
      />

      <div className="flex-1 flex flex-col">
        {/* Header */}
        <div className="bg-white border-b border-orange-200 p-4">
          <div className="flex items-center gap-3">
            <div className="w-10 h-10 bg-gradient-to-br from-orange-500 to-orange-600 rounded-full flex items-center justify-center">
              <Bot className="w-6 h-6 text-white" />
            </div>
            <div className="flex-1">
              <h1 className="text-xl font-bold text-orange-900">Sarathi AI</h1>
              <p className="text-sm text-orange-600">
                {currentLanguage === "hi"
                  ? "‡§Ü‡§™‡§ï‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï - ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§´‡•â‡§∞‡•ç‡§Æ ‡§≠‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶"
                  : currentLanguage === "kn"
                    ? "‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤∏‡≤∞‡≥ç‡≤ï‡≤æ‡≤∞‡≤ø ‡≤∏‡≤π‡≤æ‡≤Ø‡≤ï - ‡≤∏‡≤∞‡≥ç‡≤ï‡≤æ‡≤∞‡≤ø ‡≤´‡≤æ‡≤∞‡≥ç‡≤Æ‡≥ç‚Äå‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤≠‡≤∞‡≥ç‡≤§‡≤ø ‡≤Æ‡≤æ‡≤°‡≤≤‡≥Å ‡≤∏‡≤π‡≤æ‡≤Ø"
                    : currentLanguage === "ta"
                      ? "‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÖ‡Æ∞‡Æö‡Ææ‡Æô‡Øç‡Æï ‡Æâ‡Æ§‡Æµ‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç - ‡ÆÖ‡Æ∞‡Æö‡Ææ‡Æô‡Øç‡Æï ‡Æ™‡Æü‡Æø‡Æµ‡Æô‡Øç‡Æï‡Æ≥‡Øà ‡Æ®‡Æø‡Æ∞‡Æ™‡Øç‡Æ™ ‡Æâ‡Æ§‡Æµ‡Æø"
                      : currentLanguage === "te"
                        ? "‡∞∏‡∞æ‡∞∞‡∞•‡∞ø AI ‡∞®‡∞ø ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø..."
                        : currentLanguage === "bn"
                          ? "‡¶∏‡¶æ‡¶∞‡¶•‡¶ø AI ‡¶ï‡ßá ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®..."
                          : "Your Government Assistant - Help with Government Forms"}
              </p>
            </div>
            {/* TTS Status Indicator */}
            {isSpeaking && (
              <div className="flex items-center gap-2">
                <Volume2 className="w-5 h-5 text-orange-500 animate-pulse" />
                <Button
                  onClick={stopSpeech}
                  size="sm"
                  variant="outline"
                  className="border-orange-300 text-orange-700 hover:bg-orange-50"
                >
                  <VolumeX className="w-4 h-4" />
                </Button>
              </div>
            )}
          </div>
        </div>

        {/* Chat Area */}
        <ScrollArea className="flex-1 p-4">
          <div className="max-w-4xl mx-auto space-y-4">
            {messages.length === 0 && (
              <Card className="bg-gradient-to-r from-orange-100 to-orange-50 border-orange-200">
                <CardContent className="p-6">
                  <div className="text-center space-y-4">
                    <div className="w-16 h-16 bg-gradient-to-br from-orange-500 to-orange-600 rounded-full flex items-center justify-center mx-auto">
                      <Bot className="w-8 h-8 text-white" />
                    </div>
                    <h2 className="text-2xl font-bold text-orange-900">{getWelcomeMessage().title}</h2>
                    <p className="text-orange-700 max-w-2xl mx-auto">{getWelcomeMessage().description}</p>
                    <div className="flex justify-center gap-4 mt-6">
                      <FileUpload onFileUpload={handleFileUpload} />
                      <Button
                        variant="outline"
                        onClick={startVoiceRecognition}
                        disabled={isListening}
                        className="border-orange-300 text-orange-700 hover:bg-orange-50"
                      >
                        <Mic className={`w-4 h-4 mr-2 ${isListening ? "animate-pulse" : ""}`} />
                        {isListening
                          ? currentLanguage === "hi"
                            ? "‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç..."
                            : currentLanguage === "kn"
                              ? "‡≤ï‡≥á‡≤≥‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü..."
                              : "Listening..."
                          : currentLanguage === "hi"
                            ? "‡§¨‡•ã‡§≤‡•á‡§Ç"
                            : currentLanguage === "kn"
                              ? "‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤ø"
                              : "Speak"}
                      </Button>
                      {/* Test TTS Button */}
                      <Button
                        variant="outline"
                        onClick={() => handleTextToSpeech(getWelcomeMessage().title)}
                        className="border-orange-300 text-orange-700 hover:bg-orange-50"
                      >
                        <Volume2 className="w-4 h-4 mr-2" />
                        Test Voice
                      </Button>
                    </div>
                  </div>
                </CardContent>
              </Card>
            )}

            {messages.map((message) => (
              <ChatMessage
                key={message.id}
                message={message}
                onPlayAudio={handleTextToSpeech}
                language={currentLanguage}
              />
            ))}

            {isLoading && (
              <Card className="bg-white border-orange-200">
                <CardContent className="p-4">
                  <div className="flex items-center gap-3">
                    <div className="w-8 h-8 bg-gradient-to-br from-orange-500 to-orange-600 rounded-full flex items-center justify-center">
                      <Bot className="w-4 h-4 text-white" />
                    </div>
                    <div className="flex gap-1">
                      <div className="w-2 h-2 bg-orange-400 rounded-full animate-bounce" />
                      <div
                        className="w-2 h-2 bg-orange-400 rounded-full animate-bounce"
                        style={{ animationDelay: "0.1s" }}
                      />
                      <div
                        className="w-2 h-2 bg-orange-400 rounded-full animate-bounce"
                        style={{ animationDelay: "0.2s" }}
                      />
                    </div>
                  </div>
                </CardContent>
              </Card>
            )}
          </div>
        </ScrollArea>

        {/* Input Area */}
        <div className="border-t border-orange-200 bg-white p-4">
          <div className="max-w-4xl mx-auto">
            <form onSubmit={handleSubmit} className="flex gap-2">
              <div className="flex-1 relative">
                <Input
                  value={input}
                  onChange={handleInputChange}
                  placeholder={
                    currentLanguage === "hi"
                      ? "‡§∏‡§æ‡§∞‡§•‡•Ä AI ‡§∏‡•á ‡§™‡•Ç‡§õ‡•á‡§Ç..."
                      : currentLanguage === "kn"
                        ? "‡≤∏‡≤æ‡≤∞‡≤•‡≤ø AI ‡≤Ø‡≤ø‡≤Ç‡≤¶ ‡≤ï‡≥á‡≤≥‡≤ø..."
                        : currentLanguage === "ta"
                          ? "‡Æö‡Ææ‡Æ∞‡Æ§‡Æø AI ‡ÆØ‡Æø‡Æü‡ÆÆ‡Øç ‡Æï‡Øá‡Æ≥‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç..."
                          : currentLanguage === "te"
                            ? "‡∞∏‡∞æ‡∞∞‡∞•‡∞ø AI ‡∞®‡∞ø ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø..."
                            : currentLanguage === "bn"
                              ? "‡¶∏‡¶æ‡¶∞‡¶•‡¶ø AI ‡¶ï‡ßá ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®..."
                              : "Ask Sarathi AI..."
                  }
                  className="pr-20 border-orange-300 focus:border-orange-500"
                />
                <div className="absolute right-2 top-1/2 -translate-y-1/2 flex gap-1">
                  <Button
                    type="button"
                    size="sm"
                    variant="ghost"
                    onClick={startVoiceRecognition}
                    disabled={isListening}
                    className="h-8 w-8 p-0 text-orange-600 hover:bg-orange-50"
                  >
                    <Mic className={`w-4 h-4 ${isListening ? "animate-pulse" : ""}`} />
                  </Button>
                  <Button
                    type="button"
                    size="sm"
                    variant="ghost"
                    onClick={() => setShowTTSSettings(!showTTSSettings)}
                    className="h-8 w-8 p-0 text-orange-600 hover:bg-orange-50"
                  >
                    <Volume2 className="w-4 h-4" />
                  </Button>
                  <Button
                    type="button"
                    size="sm"
                    variant="ghost"
                    onClick={() => setShowDwaniLLMSettings(!showDwaniLLMSettings)}
                    className="h-8 w-8 p-0 text-orange-600 hover:bg-orange-50"
                  >
                    <Brain className="w-4 h-4" />
                  </Button>
                  <FileUpload onFileUpload={handleFileUpload} size="sm" />
                </div>
              </div>
              <Button
                type="submit"
                disabled={isLoading || !input.trim()}
                className="bg-orange-500 hover:bg-orange-600 text-white"
              >
                <Send className="w-4 h-4" />
              </Button>
            </form>

            {/* TTS Settings */}
            {showTTSSettings && (
              <div className="absolute bottom-20 right-4 z-10">
                <TTSSettings
                  language={currentLanguage}
                  onSettingsChange={setTtsSettings}
                  isOpen={showTTSSettings}
                  onToggle={() => setShowTTSSettings(false)}
                />
              </div>
            )}
            {/* Dwani LLM Settings */}
            {showDwaniLLMSettings && (
              <div className="absolute bottom-20 left-4 z-10">
                <DwaniLLMSettings
                  language={currentLanguage}
                  onSettingsChange={setDwaniLLMSettings}
                  isOpen={showDwaniLLMSettings}
                  onToggle={() => setShowDwaniLLMSettings(false)}
                />
              </div>
            )}
            {selectedFile && <div className="mt-2 text-sm text-orange-600">üìÑ {selectedFile.name} uploaded</div>}
          </div>
        </div>
      </div>
    </div>
  )
}
